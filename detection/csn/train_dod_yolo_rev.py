import os
import torch
import torch.hub
from ultralytics import YOLO
import gc

# ì´ˆê¸° ì„¤ì •
Date = "250820"
Time = "09h"  # ì‹œê°„ ì—…ë°ì´íŠ¸
User = "hwoh"
Product = "csn"
yolo_nm = "11n"
model_nm = f"{Product}_dod_{yolo_nm}_{Date}{Time}"
data_nm = "v5"

os.chdir(f"/home/{User}/detection/{Product}")
torch.hub.set_dir(f"/home/{User}/detection/{Product}")

# YOLO ëª¨ë¸ ë¡œë”© - ì™„ì „ ìë™í™”
print(f"ğŸ” YOLO ëª¨ë¸ ë¡œë”©: yolo{yolo_nm}.pt")

# Ultralyticsê°€ ì•Œì•„ì„œ ì²˜ë¦¬ (ë¡œì»¬ í™•ì¸ â†’ ìºì‹œ í™•ì¸ â†’ ë‹¤ìš´ë¡œë“œ)
model = YOLO(f"yolo{yolo_nm}.pt")

print(f"âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ: yolo{yolo_nm}.pt")
print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ: {model.ckpt_path if hasattr(model, 'ckpt_path') else 'ìºì‹œë¨'}")
        
# ëª¨ë¸ ì„¤ì •
DO_TRAIN = True
DO_VAL = False
DO_PREDICT = True

if DO_TRAIN:
    # ê°•ë ¥í•œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if torch.cuda.is_available():
        torch.cuda.set_device(0)
        for i in range(3):  # 3ë²ˆ ë°˜ë³µ ì •ë¦¬
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            gc.collect()
        
        # GPU ìƒíƒœ í™•ì¸
        device = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(0)
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        allocated = torch.cuda.memory_allocated(0) / 1024**3
        cached = torch.cuda.memory_reserved(0) / 1024**3
        
        print(f"GPU: {gpu_name}")
        print(f"Device: {device}")
        print(f"Total Memory: {total_memory:.2f}GB")
        print(f"Allocated: {allocated:.2f}GB")
        print(f"Cached: {cached:.2f}GB")
        print(f"Available: {total_memory - cached:.2f}GB")
    else:
        print("CUDA not available, using CPU")
    
    #######################
    import cv2
    ####################################################################################
    ####################################################################################
    # ë°ì´í„°ì…‹ ì´ë¯¸ì§€/ë¼ë²¨ íŒŒì¼ ì ê²€ (í™•ì¥ì ìë™ ì²˜ë¦¬)
    import os
    train_txt_path = f"/hdd/datasets/dod_data/{Product}/{data_nm}/train.txt"
    missing_images = []
    missing_labels = []

    with open(train_txt_path) as f:
        for line in f:
            img_path = line.strip()
            # ì´ë¯¸ì§€ í™•ì¥ìì™€ ìƒê´€ì—†ì´ .txtë¡œ ë³€ê²½
            label_path = os.path.splitext(img_path)[0] + ".txt"
            label_path = label_path.replace("images", "labels")
            img = cv2.imread(img_path)
            if img is None or img.size == 0:
                print(f"[X] ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {img_path}")
                missing_images.append(img_path)
            if not os.path.exists(label_path):
                print(f"[X] ë¼ë²¨ íŒŒì¼ ì—†ìŒ: {label_path}")
                missing_labels.append(label_path)

    if missing_images or missing_labels:
        print(f"[ERROR] ì†ìƒ ì´ë¯¸ì§€: {len(missing_images)}ê°œ, ë¼ë²¨ ì—†ìŒ: {len(missing_labels)}ê°œ. í•™ìŠµ ì¤‘ë‹¨.")
        exit(1)
    else:
        print("[OK] ëª¨ë“  ì´ë¯¸ì§€/ë¼ë²¨ íŒŒì¼ ì •ìƒ.")
    ####################################################################################

# í•™ìŠµ ë°ì´í„° ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ì „ ì ê²€
train_txt_path = f"/hdd/datasets/dod_data/{Product}/{data_nm}/train.txt"
missing_files = []
with open(train_txt_path) as f:
    for line in f:
        img_path = line.strip()
        img = cv2.imread(img_path)
        if img is None or img.size == 0:
            print(f"[X] ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {img_path}")
            missing_files.append(img_path)

if missing_files:
    print(f"[ERROR] ì´ {len(missing_files)}ê°œì˜ ì´ë¯¸ì§€ê°€ ì†ìƒ ë˜ëŠ” ì—†ìŒ. í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
    exit(1)
else:
    print("[OK] ëª¨ë“  í•™ìŠµ ì´ë¯¸ì§€ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë”©ë©ë‹ˆë‹¤.")
    #######################
    
    # í•™ìŠµ ì‹œì‘
    model.train(
        data=f"/hdd/datasets/dod_data/{Product}/{Product}_defect_detection_data_{data_nm}.yaml",
        epochs=500,
        batch=32,
        patience=150,
        dropout=0.22,
        iou=0.52, 
        lr0=0.0005,
        lrf=0.00001,
        optimizer="AdamW",
        workers=0, # ì›Œì»¤ ìˆ˜ ì„¤ì •
        exist_ok=True,
        project=f"/home/{User}/detection/{Product}/runs/detect",
        name=f"{model_nm}",
        verbose=True,
    )

best_weight_path = (
    f"/home/{User}/detection/{Product}/runs/detect/{model_nm}/weights/best.pt"
)

print(f"Best ê°€ì¤‘ì¹˜ ì €ì¥ ê²½ë¡œ: {best_weight_path}")

# ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” í•™ìŠµ ì™„ë£Œ í›„ í™œì„±í™”
if DO_VAL or DO_PREDICT:
    if not os.path.exists(best_weight_path):
        print(f"[ERROR] best.pt íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {best_weight_path}")
        exit(1)
    model_Product = YOLO(best_weight_path)

if DO_VAL:
    metrics = model_Product.val()
    print(metrics)
    pass

# ì˜ˆì¸¡ í›„ì²˜ë¦¬ ìˆ˜í–‰ì„ ìœ„í•œ ë³€ìˆ˜ ì„¤ì •
pre_cls = 1.0  # í´ë˜ìŠ¤ ìˆ˜ 1ê°œ ì´ìƒ
pre_kobj = 1.0  # ê°ì²´ ìˆ˜ 1ê°œ ì´ìƒ
pred_conf = 0.5  # ì‹ ë¢°ë„ 0.5 ì´ìƒ
pred_dfl = 1  # DFL ì‚¬ìš© ì—¬ë¶€ (1: ì‚¬ìš©, 0: ë¯¸ì‚¬ìš©) 

if DO_PREDICT:
    # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
    results = model_Product.predict(
        f"/hdd/datasets/dod_data/{Product}/{data_nm}/val/images",
        save=True,
        save_crop=True,
        save_txt=True,
        cls=pre_cls,
        kobj=pre_kobj,
        conf=pred_conf,
        dfl=pred_dfl,
        exist_ok=True,
        project=f"/home/{User}/detection/{Product}/runs/detect/{model_nm}",
        name=f"pred_{model_nm}_val",
    )

    ### ì‹ ë¢°ë„ ì—†ì´ ë¼ë²¨ë§Œ show_conf = False
    results = model_Product.predict(
        f"/hdd/datasets/dod_data/{Product}/{data_nm}/val/images",
        save=True,
        save_crop=True,
        save_txt=True,
        show_conf=False,
        cls=pre_cls,
        kobj=pre_kobj,
        conf=pred_conf,
        dfl=pred_dfl,
        exist_ok=True,
        project=f"/home/{User}/detection/{Product}/runs/detect/{model_nm}",
        name=f"pred_{model_nm}_val_without_conf",
    )
