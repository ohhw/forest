import os
import torch
import torch.hub
from ultralytics import YOLO
import gc
import warnings

# ì„ íƒì  ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning)

# ë©”ëª¨ë¦¬ ì•ˆì „ í™˜ê²½ë³€ìˆ˜ ì„¤ì • (expandable_segments ì œê±°)
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:32'  # expandable_segments ì œê±°
os.environ['TORCH_SERIALIZATION_WEIGHTS_ONLY'] = '0'
os.environ['OMP_NUM_THREADS'] = '2'  # ìŠ¤ë ˆë“œ ìˆ˜ ë” ê°ì†Œ
os.environ['MKL_NUM_THREADS'] = '2'
os.environ['NUMEXPR_NUM_THREADS'] = '2'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # ë™ê¸°í™” ê°•ì œ

# ë©€í‹°í”„ë¡œì„¸ì‹± ìµœì í™”
torch.multiprocessing.set_sharing_strategy('file_system')

# GPU ì„¤ì • (ì•ˆì •ì„± ìš°ì„ )
torch.backends.cudnn.enabled = False  # True â†’ False (ì•ˆì •ì„± ìš°ì„ )
torch.backends.cudnn.benchmark = False  # True â†’ False
torch.backends.cudnn.deterministic = True  # False â†’ True
torch.backends.cuda.matmul.allow_tf32 = False  # True â†’ False
torch.backends.cudnn.allow_tf32 = False  # True â†’ False

# ì´ˆê¸° ì„¤ì •
Date = "250805"
Time = "13h30m"  # ì‹œê°„ ì—…ë°ì´íŠ¸
User = "hwoh"
Product = "jjb"
yolo_nm = "11l"
model_nm = f"test_{Product}_dod_{yolo_nm}_{Date}{Time}_ultra_safe"  # ìš¸íŠ¸ë¼ ì•ˆì „ ëª¨ë“œ
data_nm = "v10"

os.chdir(f"/home/{User}/detection/{Product}")
torch.hub.set_dir(f"/home/{User}/detection/{Product}")

print("ğŸš¨ğŸš¨ğŸš¨ ìš¸íŠ¸ë¼ ì•ˆì „ ëª¨ë“œ - PyTorch ë‚´ë¶€ ì˜¤ë¥˜ ë°©ì§€ ğŸš¨ğŸš¨ğŸš¨")
print("âš™ï¸  ì„¤ì •: expandable_segments ì œê±°, cuDNN ë¹„í™œì„±í™”, ìµœì†Œ ë°°ì¹˜")

# ê°•ë ¥í•œ ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜
def aggressive_memory_cleanup():
    if torch.cuda.is_available():
        for i in range(5):  # 3 â†’ 5ë²ˆìœ¼ë¡œ ì¦ê°€
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
    gc.collect()
    
    # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œë„
    try:
        import ctypes
        libc = ctypes.CDLL("libc.so.6")
        libc.malloc_trim(0)
    except:
        pass

# ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰
aggressive_memory_cleanup()

# YOLO ê°€ì¤‘ì¹˜ ê²½ë¡œ ì„¤ì •
try:
    model = YOLO(f"/home/{User}/detection/{Product}/yolo{yolo_nm}.pt")
    print(f"ë¡œì»¬ ëª¨ë¸ ë¡œë”© ì„±ê³µ: yolo{yolo_nm}.pt")
except Exception as e:
    print(f"ë¡œì»¬ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    print("Ultralytics Hubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    model = YOLO(f"yolo{yolo_nm}.pt")

# ëª¨ë¸ ì„¤ì •
DO_TRAIN = True
DO_VAL = False
DO_PREDICT = False

if DO_TRAIN:
    # GPU ìƒíƒœ í™•ì¸
    if torch.cuda.is_available():
        torch.cuda.set_device(0)
        aggressive_memory_cleanup()  # ì¶”ê°€ ë©”ëª¨ë¦¬ ì •ë¦¬
        
        device = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(0)
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        allocated = torch.cuda.memory_allocated(0) / 1024**3
        cached = torch.cuda.memory_reserved(0) / 1024**3
        
        print(f"GPU: {gpu_name}")
        print(f"Total Memory: {total_memory:.2f}GB")
        print(f"Available: {total_memory - cached:.2f}GB")
        
        # RTX 4090 íŠ¹í™” ìš¸íŠ¸ë¼ ì•ˆì „ ì„¤ì •
        if total_memory > 40:  # A100 ë“± ê³ ì„±ëŠ¥ GPU
            batch_size = 16
            workers = 0   # 2 â†’ 0ìœ¼ë¡œ ë³€ê²½ (segfault ë°©ì§€)
            cache = False
            print("ğŸš€ ê³ ì„±ëŠ¥ GPU ê°ì§€ - ìš¸íŠ¸ë¼ ì•ˆì „ ì„¤ì •")
        elif total_memory > 20:  # RTX 3090/4090 ë“±
            batch_size = 10
            workers = 0   # 1 â†’ 0ìœ¼ë¡œ ë³€ê²½ (segfault ì™„ì „ ë°©ì§€)
            cache = False
            print("ğŸš€ RTX 4090 ê°ì§€ - ìµœëŒ€ ì•ˆì „ ì„¤ì •")
        else:  # ì¼ë°˜ GPU
            batch_size = 6
            workers = 0   # 1 â†’ 0ìœ¼ë¡œ ë³€ê²½
            cache = False
            print("ğŸš€ ì¼ë°˜ GPU ê°ì§€ - ìµœì†Œ ì„¤ì •")
            
    else:
        print("CUDA not available, using CPU")
        batch_size = 4
        workers = 0  # 1 â†’ 0ìœ¼ë¡œ ë³€ê²½
        cache = False
    
    print(f"ğŸš¨ ìš¸íŠ¸ë¼ ì•ˆì „ ëª¨ë“œ í•™ìŠµ ì‹œì‘ - batch={batch_size}, workers={workers}")
    
    # ìš¸íŠ¸ë¼ ì•ˆì „ í•™ìŠµ ì„¤ì •
    model.train(
        data=f"/hdd/datasets/dod_data/{Product}/{Product}_defect_detection_data_{data_nm}.yaml",
        epochs=300,
        batch=batch_size,  # ë§¤ìš° ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
        patience=100,
        dropout=0.22,
        iou=0.44, 
        lr0=0.0005,  # 0.001 â†’ 0.0005ë¡œ ê°ì†Œ
        lrf=0.00001,  # 0.0001 â†’ 0.00001ë¡œ ê°ì†Œ
        optimizer="AdamW",
        
        # ğŸš¨ ìš¸íŠ¸ë¼ ì•ˆì „ ì„¤ì •
        workers=workers,  # ìµœì†Œ ì›Œì»¤
        cache=cache,      # ìºì‹œ ì™„ì „ ë¹„í™œì„±í™”
        rect=False,       # True â†’ False (rectangular training ë¹„í™œì„±í™”)
        amp=False,        # True â†’ False (Mixed Precision ë¹„í™œì„±í™”)
        half=False,       # FP16 ë¹„í™œì„±í™”
        
        # ëª¨ë“  ë°ì´í„° ì¦ê°• ìµœì†Œí™”
        close_mosaic=10,  # 50 â†’ 10ìœ¼ë¡œ ë” ë¹¨ë¦¬ ë¹„í™œì„±í™”
        mixup=0.0,        # 0.05 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        copy_paste=0.0,   # 0.05 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        degrees=0.0,      # 10.0 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        translate=0.0,    # 0.1 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        scale=0.1,        # 0.3 â†’ 0.1 ìµœì†Œí™”
        shear=0.0,        # 2.0 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        perspective=0.0,  # 0.0001 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        flipud=0.0,
        fliplr=0.2,       # 0.5 â†’ 0.2ë¡œ ê°ì†Œ
        mosaic=0.0,       # 1.0 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        hsv_h=0.0,        # 0.015 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        hsv_s=0.0,        # 0.7 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        hsv_v=0.0,        # 0.4 â†’ 0.0 ì™„ì „ ë¹„í™œì„±í™”
        auto_augment=None, # "randaugment" â†’ None
        erasing=0.0,
        crop_fraction=1.0,
        
        # ì¶”ê°€ ì•ˆì „ ì„¤ì •
        single_cls=False,
        multi_scale=False,
        overlap_mask=True,
        mask_ratio=4,
        val=True,
        plots=False,      # True â†’ False (ë©”ëª¨ë¦¬ ì ˆì•½)
        save_period=50,   # 25 â†’ 50ìœ¼ë¡œ ì¦ê°€
        
        exist_ok=True,
        project=f"/home/{User}/detection/{Product}/runs/detect",
        name=f"{model_nm}",
        verbose=True,
    )

    # í•™ìŠµ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
    aggressive_memory_cleanup()

best_weight_path = (
    f"/home/{User}/detection/{Product}/runs/detect/{model_nm}/weights/best.pt"
)

print("ğŸ‰ ìš¸íŠ¸ë¼ ì•ˆì „ ëª¨ë“œ í•™ìŠµ ì™„ë£Œ!")
print(f"Best ê°€ì¤‘ì¹˜ ì €ì¥ ê²½ë¡œ: {best_weight_path}")

# ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ë™ì¼...
if DO_VAL or DO_PREDICT:
    if not os.path.exists(best_weight_path):
        print(f"[ERROR] best.pt íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {best_weight_path}")
        exit(1)
    model_Product = YOLO(best_weight_path)

if DO_VAL:
    metrics = model_Product.val()
    print(metrics)

# ì˜ˆì¸¡ ì„¤ì •
pre_cls = 1.0
pre_kobj = 1.0
pred_conf = 0.5
pred_dfl = 1

if DO_PREDICT:
    # ì˜ˆì¸¡ ìˆ˜í–‰
    results = model_Product.predict(
        f"/hdd/datasets/dod_data/{Product}/{data_nm}/val/images",
        save=True,
        save_crop=True,
        save_txt=True,
        cls=pre_cls,
        kobj=pre_kobj,
        conf=pred_conf,
        dfl=pred_dfl,
        exist_ok=True,
        project=f"/home/{User}/detection/{Product}/runs/detect/{model_nm}",
        name=f"pred_{model_nm}_val",
    )

    # ì‹ ë¢°ë„ ì—†ì´ ì˜ˆì¸¡
    results = model_Product.predict(
        f"/hdd/datasets/dod_data/{Product}/{data_nm}/val/images",
        save=True,
        save_crop=True,
        save_txt=True,
        show_conf=False,
        cls=pre_cls,
        kobj=pre_kobj,
        conf=pred_conf,
        dfl=pred_dfl,
        exist_ok=True,
        project=f"/home/{User}/detection/{Product}/runs/detect/{model_nm}",
        name=f"pred_{model_nm}_val_without_conf",
    )