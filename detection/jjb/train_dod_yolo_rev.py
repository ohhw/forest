import os
import torch
import torch.hub
from ultralytics import YOLO
import gc

# # ê°•í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì•ˆì •ì„± ì„¤ì •
# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:64'  # ë” ì‘ê²Œ
# os.environ['TORCH_SERIALIZATION_WEIGHTS_ONLY'] = '0'  # weights_only ë¬¸ì œ í•´ê²°
# os.environ['OMP_NUM_THREADS'] = '4'  # OpenMP ì“°ë ˆë“œ ì œí•œ
# os.environ['MKL_NUM_THREADS'] = '4'  # MKL ì“°ë ˆë“œ ì œí•œ

# # GPU ë©”ëª¨ë¦¬ ë° OpenCV ìµœì í™” ì„¤ì • (ë” ë³´ìˆ˜ì ìœ¼ë¡œ)
# torch.backends.cudnn.benchmark = False
# torch.backends.cudnn.deterministic = True
# torch.backends.cuda.matmul.allow_tf32 = False  # ì •í™•ì„± ìš°ì„ 
# torch.backends.cudnn.allow_tf32 = False

# # ë©€í‹°í”„ë¡œì„¸ì‹± ì•ˆì „ ì„¤ì •
# torch.multiprocessing.set_sharing_strategy('file_system')
# torch.multiprocessing.set_start_method('spawn', force=True)  # ì¶”ê°€

# ì´ˆê¸° ì„¤ì •
Date = "250807"
Time = "10h30m"  # ì‹œê°„ ì—…ë°ì´íŠ¸
User = "hwoh"
Product = "csn"
yolo_nm = "11n"
# model_nm = f"test_{Product}_dod_{yolo_nm}_{Date}{Time}_safe"  # ì•ˆì „ ëª¨ë“œ í‘œì‹œ
model_nm = f"{Product}_dod_{yolo_nm}_{Date}{Time}"
data_nm = "v5"

os.chdir(f"/home/{User}/detection/{Product}")
torch.hub.set_dir(f"/home/{User}/detection/{Product}")

# YOLO ê°€ì¤‘ì¹˜ ê²½ë¡œ ì„¤ì • - ê³µí†µ í´ë” ì‚¬ìš©
try:
    # ê³µí†µ ê°€ì¤‘ì¹˜ í´ë”ì—ì„œ ë¨¼ì € ì°¾ê¸°
    common_model_path = f"/home/{User}/yolo_models/yolo{yolo_nm}.pt"
    if os.path.exists(common_model_path):
        model = YOLO(common_model_path)
        print(f"âœ… ê³µí†µ ëª¨ë¸ ë¡œë”© ì„±ê³µ: {common_model_path}")
    else:
        # ê³µí†µ í´ë”ì— ì—†ìœ¼ë©´ ë¡œì»¬ì—ì„œ ì°¾ê¸°
        local_model_path = f"/home/{User}/detection/{Product}/yolo{yolo_nm}.pt"
        if os.path.exists(local_model_path):
            model = YOLO(local_model_path)
            print(f"âœ… ë¡œì»¬ ëª¨ë¸ ë¡œë”© ì„±ê³µ: {local_model_path}")
        else:
            raise FileNotFoundError("ë¡œì»¬ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
            
except Exception as e:
    print(f"âŒ ë¡œì»¬ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    print("ğŸŒ Ultralytics Hubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    model = YOLO(f"yolo{yolo_nm}.pt")
    
    # ë‹¤ìš´ë¡œë“œ ì„±ê³µí•˜ë©´ ê³µí†µ í´ë”ì— ì €ì¥
    try:
        os.makedirs("/home/hwoh/yolo_models", exist_ok=True)
        model.save(f"/home/{User}/yolo_models/yolo{yolo_nm}.pt")
        print(f"ğŸ“¦ ëª¨ë¸ì„ ê³µí†µ í´ë”ì— ì €ì¥: /home/{User}/yolo_models/yolo{yolo_nm}.pt")
    except Exception as save_error:
        print(f"âš ï¸ ê³µí†µ í´ë” ì €ì¥ ì‹¤íŒ¨: {save_error}")
        
# ëª¨ë¸ ì„¤ì •
DO_TRAIN = True
DO_VAL = False
DO_PREDICT = False  # í•™ìŠµ ì™„ë£Œ í›„ í™œì„±í™”

if DO_TRAIN:
    # ê°•ë ¥í•œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if torch.cuda.is_available():
        torch.cuda.set_device(0)
        for i in range(3):  # 3ë²ˆ ë°˜ë³µ ì •ë¦¬
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            gc.collect()
        
        # GPU ìƒíƒœ í™•ì¸
        device = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(0)
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        allocated = torch.cuda.memory_allocated(0) / 1024**3
        cached = torch.cuda.memory_reserved(0) / 1024**3
        
        print(f"GPU: {gpu_name}")
        print(f"Device: {device}")
        print(f"Total Memory: {total_memory:.2f}GB")
        print(f"Allocated: {allocated:.2f}GB")
        print(f"Cached: {cached:.2f}GB")
        print(f"Available: {total_memory - cached:.2f}GB")
    else:
        print("CUDA not available, using CPU")
    
    # print("ğŸš¨ Segmentation fault ë°©ì§€ ëª¨ë“œë¡œ í•™ìŠµ ì‹œì‘...")
    # print("âš™ï¸  ì•ˆì „ ì„¤ì •: workers=0, batch=16, ëª¨ë“  ì¦ê°• ìµœì†Œí™”")
    
    # ì•ˆì „ ëª¨ë“œ í•™ìŠµ (Segmentation fault ë°©ì§€)
    model.train(
        data=f"/hdd/datasets/dod_data/{Product}/{Product}_defect_detection_data_{data_nm}.yaml",
        epochs=300,
        batch=16,  # ë” ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
        patience=100,
        dropout=0.22,
        iou=0.44, 
        lr0=0.0005,
        lrf=0.00001,
        optimizer="AdamW",
        
        # # ğŸš¨ Segmentation fault ë°©ì§€ í•µì‹¬ ì„¤ì •
        # workers=0,  # ë©€í‹°í”„ë¡œì„¸ì‹± ì™„ì „ ë¹„í™œì„±í™”
        # cache=False,  # ìºì‹œ ë¹„í™œì„±í™”
        # rect=False,  # rectangular training ë¹„í™œì„±í™”
        # amp=False,  # AMP ë¹„í™œì„±í™” (ì•ˆì •ì„± ìš°ì„ )
        
        # # ë°ì´í„° ì¦ê°• ìµœì†Œí™” (ë©”ëª¨ë¦¬ ì ‘ê·¼ ì˜¤ë¥˜ ë°©ì§€)
        # close_mosaic=10,
        # mixup=0.0,
        # copy_paste=0.0,
        # degrees=0.0,  # íšŒì „ ì™„ì „ ë¹„í™œì„±í™”
        # translate=0.0,  # ì´ë™ ì™„ì „ ë¹„í™œì„±í™”
        # scale=0.1,  # ìŠ¤ì¼€ì¼ ìµœì†Œí™”
        # shear=0.0,  # ì „ë‹¨ ë³€í™˜ ë¹„í™œì„±í™”
        # perspective=0.0,  # perspective ë³€í™˜ ë¹„í™œì„±í™”
        # flipud=0.0,  # ìƒí•˜ ë’¤ì§‘ê¸° ë¹„í™œì„±í™”
        # fliplr=0.2,  # ì¢Œìš° ë’¤ì§‘ê¸° ìµœì†Œí™”
        # mosaic=0.0,  # mosaic ì™„ì „ ë¹„í™œì„±í™”
        # hsv_h=0.0,  # HSV ë³€í™” ë¹„í™œì„±í™”
        # hsv_s=0.0,  # HSV ì±„ë„ ë³€í™” ë¹„í™œì„±í™”
        # hsv_v=0.0,  # HSV ëª…ë„ ë³€í™” ë¹„í™œì„±í™”
        # auto_augment=None,  # ìë™ ì¦ê°• ë¹„í™œì„±í™”
        # erasing=0.0,  # random erasing ë¹„í™œì„±í™”
        # crop_fraction=1.0,  # crop ë¹„í™œì„±í™”
        
        exist_ok=True,
        project=f"/home/{User}/detection/{Product}/runs/detect",
        name=f"{model_nm}",
        verbose=True,  # ìì„¸í•œ ë¡œê·¸ ì¶œë ¥
    )

best_weight_path = (
    f"/home/{User}/detection/{Product}/runs/detect/{model_nm}/weights/best.pt"
)

# print("ğŸ‰ ì•ˆì „ ëª¨ë“œ í•™ìŠµ ì™„ë£Œ!")
print(f"Best ê°€ì¤‘ì¹˜ ì €ì¥ ê²½ë¡œ: {best_weight_path}")

# ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” í•™ìŠµ ì™„ë£Œ í›„ í™œì„±í™”
if DO_VAL or DO_PREDICT:
    if not os.path.exists(best_weight_path):
        print(f"[ERROR] best.pt íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {best_weight_path}")
        exit(1)
    model_Product = YOLO(best_weight_path)


if DO_VAL:
    metrics = model_Product.val()
    print(metrics)
    pass


# ì˜ˆì¸¡ í›„ì²˜ë¦¬ ìˆ˜í–‰ì„ ìœ„í•œ ë³€ìˆ˜ ì„¤ì •
pre_cls = 1.0  # í´ë˜ìŠ¤ ìˆ˜ 1ê°œ ì´ìƒ
pre_kobj = 1.0  # ê°ì²´ ìˆ˜ 1ê°œ ì´ìƒ
pred_conf = 0.5  # ì‹ ë¢°ë„ 0.5 ì´ìƒ
pred_dfl = 1  # DFL ì‚¬ìš© ì—¬ë¶€ (1: ì‚¬ìš©, 0: ë¯¸ì‚¬ìš©) 


if DO_PREDICT:
    # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
    results = model_Product.predict(
        f"/hdd/datasets/dod_data/{Product}/{data_nm}/val/images",
        save=True,
        save_crop=True,
        save_txt=True,
        cls=pre_cls,
        kobj=pre_kobj,
        conf=pred_conf,
        dfl=pred_dfl,
        exist_ok=True, # ê¸°ì¡´ ê²°ê³¼ ë®ì–´ì“°ê¸°
        project=f"/home/{User}/detection/{Product}/runs/detect/{model_nm}",
        name=f"pred_{model_nm}_val",
        # name=f"pred_{model_nm}_val_finetune",  # ê¸°ì¡´ê³¼ ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì§€ì •
    )

    ### ì‹ ë¢°ë„ ì—†ì´ ë¼ë²¨ë§Œ show_conf = False
    # show_conf=FalseëŠ” ê²°ê³¼ ì´ë¯¸ì§€ì—ë§Œ ì ìš©ë¨. save_txt=Trueë¡œ ì €ì¥ë˜ëŠ” txtì—ëŠ” confê°€ í•­ìƒ í¬í•¨ë¨.
    # txtì—ì„œ confë¥¼ ì œê±°í•˜ë ¤ë©´ ë³„ë„ í›„ì²˜ë¦¬ í•„ìš”.
    results = model_Product.predict(
        f"/hdd/datasets/dod_data/{Product}/{data_nm}/val/images",
        save=True,
        save_crop=True,
        save_txt=True,
        show_conf=False,  # ì´ë¯¸ì§€ì— ì‹ ë¢°ë„ ë¯¸í‘œì‹œ (txtì—ëŠ” í•­ìƒ conf í¬í•¨)
        cls=pre_cls,
        kobj=pre_kobj,
        conf=pred_conf,
        dfl=pred_dfl,
        exist_ok=True,
        project=f"/home/{User}/detection/{Product}/runs/detect/{model_nm}",
        name=f"pred_{model_nm}_val_without_conf",
        # name=f"pred_{model_nm}_val_without_conf_finetune",  # ê¸°ì¡´ê³¼ ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì§€ì •
    )
