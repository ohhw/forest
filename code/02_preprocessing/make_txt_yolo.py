"""
YOLO ë°ì´í„°ì…‹ ê²½ë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±ê¸°
train.txt, valid.txt, test.txt íŒŒì¼ì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import argparse
from glob import glob
from pathlib import Path
from typing import List, Set


# ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì
DEFAULT_IMAGE_EXTENSIONS = [
    "bmp", "jpg", "jpeg", "png", "tif", "tiff", "webp",
    "BMP", "JPG", "JPEG", "PNG", "TIF", "TIFF", "WEBP"
]


def collect_images(base_dir: str, extensions: List[str] = None, recursive: bool = False) -> List[str]:
    """
    ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        base_dir: ì´ë¯¸ì§€ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        extensions: ì´ë¯¸ì§€ í™•ì¥ì ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        recursive: í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ ê²€ìƒ‰í• ì§€ ì—¬ë¶€
        
    Returns:
        ì´ë¯¸ì§€ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    if not os.path.exists(base_dir):
        print(f"âš ï¸  ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_dir}")
        return []
    
    if extensions is None:
        extensions = DEFAULT_IMAGE_EXTENSIONS
    
    image_list = []
    pattern = "**/*" if recursive else "*"
    
    for ext in extensions:
        search_pattern = os.path.join(base_dir, f"{pattern}.{ext}")
        found = glob(search_pattern, recursive=recursive)
        image_list.extend(found)
    
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ ë° ì¤‘ë³µ ì œê±°
    image_list = [os.path.abspath(path) for path in image_list]
    
    return image_list


def remove_duplicates(image_list: List[str]) -> List[str]:
    """ì¤‘ë³µëœ ì´ë¯¸ì§€ ê²½ë¡œ ì œê±° (ìˆœì„œ ìœ ì§€)"""
    seen = set()
    result = []
    for path in image_list:
        if path not in seen:
            seen.add(path)
            result.append(path)
    return result


def save_image_list(image_list: List[str], output_path: str, create_dirs: bool = True) -> bool:
    """
    ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        image_list: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        create_dirs: ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±í• ì§€ ì—¬ë¶€
        
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        if create_dirs:
            output_dir = os.path.dirname(output_path)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
        
        # íŒŒì¼ ì €ì¥
        with open(output_path, "w") as f:
            if image_list:
                f.write("\n".join(image_list) + "\n")
            else:
                f.write("")  # ë¹ˆ íŒŒì¼ ìƒì„±
        
        return True
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def create_dataset_txt(
    product: str,
    data_version: str,
    base_path: str = "/hdd/datasets",
    data_type: str = "dod_data",
    splits: List[str] = ["train", "val", "test"],
    extra_dirs: List[str] = None,
    output_dir: str = None,
    recursive: bool = False,
    verbose: bool = False
):
    """
    YOLO ë°ì´í„°ì…‹ì˜ train.txt, valid.txt, test.txt íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        product: ì œí’ˆëª… (ì˜ˆ: jjb, csn, wln, obj)
        data_version: ë°ì´í„° ë²„ì „ (ì˜ˆ: v8, v10, 251015_psm)
        base_path: ë°ì´í„°ì…‹ ê¸°ë³¸ ê²½ë¡œ
        data_type: ë°ì´í„° íƒ€ì… (dod_data, cls_data, obj_data ë“±)
        splits: ìƒì„±í•  split ë¦¬ìŠ¤íŠ¸ (train, val, test)
        extra_dirs: ì¶”ê°€ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ (Noneì´ë©´ ìë™ ì„¤ì •)
        recursive: í•˜ìœ„ í´ë”ê¹Œì§€ ê²€ìƒ‰í• ì§€ ì—¬ë¶€
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“‹ YOLO ë°ì´í„°ì…‹ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±")
    print(f"{'='*70}")
    print(f"ì œí’ˆ: {product}")
    print(f"ë²„ì „: {data_version}")
    print(f"ë°ì´í„° íƒ€ì…: {data_type}")
    print(f"Split: {', '.join(splits)}")
    print(f"{'='*70}\n")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if output_dir is None:
        output_dir = os.path.join(base_path, data_type, product, data_version)
    
    results = {}
    
    for split in splits:
        print(f"ğŸ“‚ {split.upper()} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        # ê¸°ë³¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        main_dir = os.path.join(base_path, data_type, product, data_version, split, "images")
        image_list = collect_images(main_dir, recursive=recursive)
        
        if verbose:
            print(f"  - ê¸°ë³¸ ê²½ë¡œ: {main_dir} ({len(image_list)}ê°œ)")
        
        # ì¶”ê°€ ë””ë ‰í† ë¦¬ ì²˜ë¦¬ (trainë§Œ í•´ë‹¹)
        if split == "train" and extra_dirs:
            print(f"  â• ì¶”ê°€ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘ ì¤‘...")
            for extra_dir in extra_dirs:
                # ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹ˆë©´ ê¸°ë³¸ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
                if not os.path.isabs(extra_dir):
                    extra_dir = os.path.join(base_path, data_type, product, extra_dir)
                
                extra_images = collect_images(extra_dir, recursive=recursive)
                image_list.extend(extra_images)
                
                if verbose:
                    print(f"  - ì¶”ê°€ ê²½ë¡œ: {extra_dir} ({len(extra_images)}ê°œ)")
        
        # ì¤‘ë³µ ì œê±°
        original_count = len(image_list)
        image_list = remove_duplicates(image_list)
        duplicates = original_count - len(image_list)
        
        if duplicates > 0:
            print(f"  ğŸ”„ ì¤‘ë³µ ì œê±°: {duplicates}ê°œ")
        
        # íŒŒì¼ ì €ì¥
        output_name = "valid.txt" if split == "val" else f"{split}.txt"
        output_path = os.path.join(output_dir, output_name)
        
        if save_image_list(image_list, output_path):
            print(f"  âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
            print(f"  ğŸ“Š ì´ë¯¸ì§€ ìˆ˜: {len(image_list)}ê°œ\n")
            results[split] = {
                "count": len(image_list),
                "path": output_path,
                "success": True
            }
        else:
            print(f"  âŒ ì €ì¥ ì‹¤íŒ¨\n")
            results[split] = {
                "count": len(image_list),
                "path": output_path,
                "success": False
            }
    
    # ê²°ê³¼ ìš”ì•½
    print(f"{'='*70}")
    print(f"ğŸ“Š ìƒì„± ê²°ê³¼ ìš”ì•½")
    print(f"{'='*70}")
    
    total_images = 0
    for split, result in results.items():
        status = "âœ…" if result["success"] else "âŒ"
        split_name = "valid" if split == "val" else split
        print(f"{status} {split_name}.txt: {result['count']:,}ê°œ ì´ë¯¸ì§€")
        if result["success"]:
            total_images += result["count"]
    
    print(f"\nğŸ“ ì¶œë ¥ ìœ„ì¹˜: {output_dir}")
    print(f"ğŸ¯ ì „ì²´ ì´ë¯¸ì§€: {total_images:,}ê°œ")
    print(f"{'='*70}\n")


def main():
    parser = argparse.ArgumentParser(
        description="YOLO ë°ì´í„°ì…‹ ê²½ë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±ê¸°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‚¬ìš© (train, val, test ëª¨ë‘ ìƒì„±)
  python make_txt_yolo.py --product jjb --version v10
  
  # trainë§Œ ìƒì„±
  python make_txt_yolo.py --product csn --version v8 --splits train
  
  # ì¶”ê°€ ë””ë ‰í† ë¦¬ í¬í•¨
  python make_txt_yolo.py --product jjb --version v10 --extra-dirs 250529_add_data/images 250916_add_data/images
  
  # ì¶œë ¥ ê²½ë¡œ ì§€ì •
  python make_txt_yolo.py --product obj --version 251015_psm --data-type obj_data --output-dir /hdd/datasets/obj_data/251015_psm
  
  # í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ ê²€ìƒ‰
  python make_txt_yolo.py --product wln --version v5 --recursive
        """
    )
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument(
        "--product", "-p",
        type=str,
        required=True,
        help="ì œí’ˆëª… (ì˜ˆ: jjb, csn, wln, obj)"
    )
    parser.add_argument(
        "--version", "-v",
        type=str,
        required=True,
        help="ë°ì´í„° ë²„ì „ (ì˜ˆ: v8, v10, 251015_psm)"
    )
    
    # ì„ íƒ ì¸ì
    parser.add_argument(
        "--base-path",
        type=str,
        default="/hdd/datasets",
        help="ë°ì´í„°ì…‹ ê¸°ë³¸ ê²½ë¡œ (ê¸°ë³¸ê°’: /hdd/datasets)"
    )
    parser.add_argument(
        "--data-type",
        type=str,
        default="dod_data",
        help="ë°ì´í„° íƒ€ì… (ê¸°ë³¸ê°’: dod_data, ì˜ˆ: cls_data, obj_data)"
    )
    parser.add_argument(
        "--splits",
        nargs="+",
        default=["train", "val", "test"],
        choices=["train", "val", "test"],
        help="ìƒì„±í•  split (ê¸°ë³¸ê°’: train val test)"
    )
    parser.add_argument(
        "--extra-dirs",
        nargs="+",
        help="ì¶”ê°€ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (trainì—ë§Œ ì ìš©, ìƒëŒ€ê²½ë¡œ ë˜ëŠ” ì ˆëŒ€ê²½ë¡œ)"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        help="ì¶œë ¥ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ìë™ ì„¤ì •)"
    )
    parser.add_argument(
        "--recursive", "-r",
        action="store_true",
        help="í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ ê²€ìƒ‰"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="ìƒì„¸ ì¶œë ¥"
    )
    
    args = parser.parse_args()
    
    # ì‹¤í–‰
    create_dataset_txt(
        product=args.product,
        data_version=args.version,
        base_path=args.base_path,
        data_type=args.data_type,
        splits=args.splits,
        extra_dirs=args.extra_dirs,
        output_dir=args.output_dir,
        recursive=args.recursive,
        verbose=args.verbose
    )


if __name__ == "__main__":
    main()